{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flask_Trial 1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOnt29zCyaRiJ2sWQLqjzF1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ismail-Ryad/image-colourization/blob/master/Flask_Trial_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPq6pVpOOPsK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff62a6cb-2a12-42e8-bde0-24f4419cb617"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVaMm-3pS7t6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKD86lP4PpSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flask import Flask, jsonify, request, send_file, render_template\n",
        "from PIL import Image\n",
        "import io\n",
        "import numpy as np\n",
        "import torch\n",
        "import requests\n",
        "import base64\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import sys\n",
        "sys.path.append(\".\")\n",
        "\n",
        "#from api.utils import exif_transpose\n",
        "import PIL.Image\n",
        "import PIL.ImageOps\n",
        "\n",
        "\n",
        "class ColorizationUpsampling(nn.Module):\n",
        "  def __init__(self, input_size=128):\n",
        "    super(ColorizationUpsampling, self).__init__()\n",
        "    MIDLEVEL_FEATURE_SIZE = 128\n",
        "\n",
        "    ## Encoder\n",
        "    resnet = models.resnet18()\n",
        "    resnet.conv1.weight = nn.Parameter(resnet.conv1.weight.sum(dim=1).unsqueeze(1)) \n",
        "    self.midlevel_resnet = nn.Sequential(*list(resnet.children())[0:6])\n",
        "\n",
        "    ## Upsampling\n",
        "    self.upsample = nn.Sequential(     \n",
        "      nn.Conv2d(MIDLEVEL_FEATURE_SIZE, 128, kernel_size=3, stride=1, padding=1),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.ReLU(),\n",
        "      nn.Upsample(scale_factor=2),\n",
        "      nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.Upsample(scale_factor=2),\n",
        "      nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
        "      nn.BatchNorm2d(32),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(32, 2, kernel_size=3, stride=1, padding=1),\n",
        "      nn.Upsample(scale_factor=2)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    ## Encoder\n",
        "    x = self.midlevel_resnet(x)\n",
        "    ## Decoder\n",
        "    x = self.upsample(x)\n",
        "    return x\n",
        "\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import torchvision.transforms.functional as TF\n",
        "import numpy as np\n",
        "import torch\n",
        "from skimage.color import lab2rgb, rgb2gray\n",
        "#from model import ColorizationUpsampling\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def colorizer():\n",
        "    \"\"\"\n",
        "    Predict and show color image from input image\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    path = '/content/drive/My Drive/test/gray/img-1-epoch-18.jpg'\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((224,224))\n",
        "    img_original = np.array(img)\n",
        "\n",
        "    gray = rgb2gray(img_original)\n",
        "    x = TF.to_tensor(gray).float()\n",
        "    x.unsqueeze_(0)\n",
        "    model = ColorizationUpsampling()\n",
        "    model.load_state_dict(torch.load('/content/drive/My Drive/colorization_models/checkpoints/model-epoch-22-losses-0.002910.pth',\n",
        "                                     map_location=torch.device('cpu')))\n",
        "\n",
        "    output = model(x)\n",
        "\n",
        "    output = output.detach()\n",
        "    color_image = torch.cat((x[0], output[0]), 0).numpy()\n",
        "    color_image = color_image.transpose((1, 2, 0))  # rescale for matplotlib\n",
        "    color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100\n",
        "    color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128\n",
        "    color_image = lab2rgb(color_image.astype(np.float16))\n",
        "\n",
        "    color_image_bgr = color_image.astype(np.float32)\n",
        "    color_image_bgr = cv2.cvtColor(color_image_bgr, cv2.COLOR_RGB2BGR)\n",
        "    color_image_bgr = cv2.resize(color_image_bgr, (380, 240))\n",
        "\n",
        "    normalized_array = (color_image_bgr - np.min(color_image_bgr)) / (\n",
        "            np.max(color_image_bgr) - np.min(color_image_bgr))  # this set the range from 0 till 1\n",
        "    color_image_bgr = (normalized_array * 255).astype(np.uint8)\n",
        "    gray = cv2.resize(gray, (380, 240))\n",
        "    gray = np.stack((gray,) * 3, axis=-1)\n",
        "\n",
        "    gray = (gray - np.min(gray)) / (\n",
        "            np.max(gray) - np.min(gray))  # this set the range from 0 till 1\n",
        "    gray = (gray * 255).astype(np.uint8)\n",
        "    vis = np.concatenate((gray, color_image_bgr), axis=1)\n",
        "\n",
        "    frame_normed = np.array(vis, np.uint8)\n",
        "\n",
        "    cv2.imwrite(path[:-4]+\"out.jpg\", frame_normed)\n",
        "   # cv2_imshow(frame_normed)\n",
        "   # cv2.waitKey(0)\n",
        "    #cv2.destroyAllWindows()\n",
        "    return frame_normed\n",
        "def exif_transpose(img: PIL.Image) -> PIL.Image:\n",
        "    \"\"\"\n",
        "    Source: https://github.com/ageitgey/image_to_numpy/blob/master/image_to_numpy/src.py\n",
        "    \"\"\"\n",
        "\n",
        "    exif_orientation_tag = 274\n",
        "\n",
        "    # Check for EXIF data (only present on some files)\n",
        "    if hasattr(img, \"_getexif\") and isinstance(img._getexif(), dict) and exif_orientation_tag in img._getexif():\n",
        "        exif_data = img._getexif()\n",
        "        orientation = exif_data[exif_orientation_tag]\n",
        "\n",
        "        # Handle EXIF Orientation\n",
        "        if orientation == 1:\n",
        "            # Normal image - nothing to do!\n",
        "            pass\n",
        "        elif orientation == 2:\n",
        "            # Mirrored left to right\n",
        "            img = img.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
        "        elif orientation == 3:\n",
        "            # Rotated 180 degrees\n",
        "            img = img.rotate(180)\n",
        "        elif orientation == 4:\n",
        "            # Mirrored top to bottom\n",
        "            img = img.rotate(180).transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
        "        elif orientation == 5:\n",
        "            # Mirrored along top-left diagonal\n",
        "            img = img.rotate(-90, expand=True).transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
        "        elif orientation == 6:\n",
        "            # Rotated 90 degrees\n",
        "            img = img.rotate(-90, expand=True)\n",
        "        elif orientation == 7:\n",
        "            # Mirrored along top-right diagonal\n",
        "            img = img.rotate(90, expand=True).transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
        "        elif orientation == 8:\n",
        "            # Rotated 270 degrees\n",
        "            img = img.rotate(90, expand=True)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "@app.route('/', methods=['GET'])\n",
        "def home():\n",
        "    return render_template('home.html')\n",
        "\n",
        "\n",
        "@app.route('/result', methods=['POST'])\n",
        "def result_page():\n",
        "    output_img_io = colorizer(request=request, img_name=\"img\")\n",
        "    jpg_as_text = base64.b64encode(output_img_io.getvalue()).decode()\n",
        "    return render_template('result.html', photo=jpg_as_text)\n",
        "\n",
        "\n",
        "@app.route('/check_image', methods=['POST'])\n",
        "def check_image():\n",
        "    if request.files.get(\"image\"):\n",
        "\n",
        "        image = request.files[\"image\"].read()\n",
        "        image = Image.open(io.BytesIO(image))\n",
        "        input_array = np.asarray(image)\n",
        "\n",
        "        return jsonify({\n",
        "            \"image_shape\": input_array.shape,\n",
        "            \"is_grayscale_image\": len(input_array.shape) == 2,\n",
        "        })\n",
        "\n",
        "\n",
        "@app.route('/colorize', methods=['POST'])\n",
        "def colorize():\n",
        "    if request.files.get(\"image\"):\n",
        "        output_img_io = colorizer(request=request, img_name=\"image\")\n",
        "        return send_file(output_img_io, mimetype='image/png')\n",
        "\n",
        "    else:\n",
        "        response = jsonify({\n",
        "            \"message\": \"An image file is required\"\n",
        "        })\n",
        "        response.status_code = 401\n",
        "        return response\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdabvEkTSNOl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "dd042d96-cc8a-4d64-a795-cb2192d9fee5"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True,use_reloader=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: on\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-_RJoexn7Ya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}